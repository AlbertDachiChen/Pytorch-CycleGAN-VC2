{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import time\n",
    "import librosa\n",
    "import pickle\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "import preprocess\n",
    "from trainingDataset import trainingDataset\n",
    "from model_VC2 import Generator, Discriminator#, Encoder, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "class GLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GLU, self).__init__()\n",
    "        # Custom Implementation because the Voice Conversion Cycle GAN\n",
    "        # paper assumes GLU won't reduce the dimension of tensor by 2.\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input * torch.sigmoid(input)\n",
    "\n",
    "\n",
    "class up_2Dsample(nn.Module):\n",
    "    def __init__(self, upscale_factor=2):\n",
    "        super(up_2Dsample, self).__init__()\n",
    "        self.scale_factor = upscale_factor\n",
    "\n",
    "    def forward(self, input):\n",
    "        h = input.shape[2]\n",
    "        w = input.shape[3]\n",
    "        new_size = [h * self.scale_factor, w * self.scale_factor]\n",
    "        return F.interpolate(input,new_size)\n",
    "       \n",
    "\n",
    "class PixelShuffle(nn.Module):\n",
    "    def __init__(self, upscale_factor=2):\n",
    "        super(PixelShuffle, self).__init__()\n",
    "        # Custom Implementation because PyTorch PixelShuffle requires,\n",
    "        # 4D input. Whereas, in this case we have have 3D array\n",
    "        self.upscale_factor = upscale_factor\n",
    "\n",
    "    def forward(self, input):\n",
    "        n = input.shape[0]\n",
    "        c_out = input.shape[1] // self.upscale_factor\n",
    "        w_new = input.shape[2] * self.upscale_factor\n",
    "        return input.view(n, c_out, w_new)\n",
    "\n",
    "\n",
    "class ResidualLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(ResidualLayer, self).__init__()\n",
    "        self.conv1d_layer = nn.Sequential(nn.Conv1d(in_channels=in_channels,\n",
    "                                                    out_channels=out_channels,\n",
    "                                                    kernel_size=kernel_size,\n",
    "                                                    stride=1,\n",
    "                                                    padding=padding),\n",
    "                                          nn.InstanceNorm1d(num_features=out_channels,\n",
    "                                                            affine=True))\n",
    "\n",
    "        self.conv_layer_gates = nn.Sequential(nn.Conv1d(in_channels=in_channels,\n",
    "                                                        out_channels=out_channels,\n",
    "                                                        kernel_size=kernel_size,\n",
    "                                                        stride=1,\n",
    "                                                        padding=padding),\n",
    "                                              nn.InstanceNorm1d(num_features=out_channels,\n",
    "                                                                affine=True))\n",
    "\n",
    "        self.conv1d_out_layer = nn.Sequential(nn.Conv1d(in_channels=out_channels,\n",
    "                                                        out_channels=in_channels,\n",
    "                                                        kernel_size=kernel_size,\n",
    "                                                        stride=1,\n",
    "                                                        padding=padding),\n",
    "                                              nn.InstanceNorm1d(num_features=in_channels,\n",
    "                                                                affine=True))\n",
    "\n",
    "    def forward(self, input):\n",
    "        h1_norm = self.conv1d_layer(input)\n",
    "        h1_gates_norm = self.conv_layer_gates(input)\n",
    "\n",
    "        # GLU\n",
    "        h1_glu = h1_norm * torch.sigmoid(h1_gates_norm)\n",
    "\n",
    "        h2_norm = self.conv1d_out_layer(h1_glu)\n",
    "        return input + h2_norm\n",
    "\n",
    "\n",
    "class downSample_Generator(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(downSample_Generator, self).__init__()\n",
    "\n",
    "        self.convLayer = nn.Sequential(nn.Conv2d(in_channels=in_channels,\n",
    "                                                 out_channels=out_channels,\n",
    "                                                 kernel_size=kernel_size,\n",
    "                                                 stride=stride,\n",
    "                                                 padding=padding),\n",
    "                                       nn.InstanceNorm2d(num_features=out_channels,\n",
    "                                                         affine=True))\n",
    "        self.convLayer_gates = nn.Sequential(nn.Conv2d(in_channels=in_channels,\n",
    "                                                       out_channels=out_channels,\n",
    "                                                       kernel_size=kernel_size,\n",
    "                                                       stride=stride,\n",
    "                                                       padding=padding),\n",
    "                                             nn.InstanceNorm2d(num_features=out_channels,\n",
    "                                                               affine=True))\n",
    "\n",
    "    def forward(self, input):\n",
    "        a = self.convLayer(input)\n",
    "        b = self.convLayer_gates(input)\n",
    "        return self.convLayer(input) * torch.sigmoid(self.convLayer_gates(input))\n",
    "\n",
    "\n",
    "class upSample_Generator(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(upSample_Generator, self).__init__()\n",
    "\n",
    "        self.convLayer = nn.Sequential(nn.Conv2d(in_channels=in_channels,\n",
    "                                                 out_channels=out_channels,\n",
    "                                                 kernel_size=kernel_size,\n",
    "                                                 stride=stride,\n",
    "                                                 padding=padding),\n",
    "                                       #PixelShuffle(upscale_factor=2),\n",
    "                                       up_2Dsample(upscale_factor=2),\n",
    "                                       nn.InstanceNorm2d(num_features=out_channels,\n",
    "                                                         affine=True))\n",
    "        self.convLayer_gates = nn.Sequential(nn.Conv2d(in_channels=in_channels,\n",
    "                                                       out_channels=out_channels,\n",
    "                                                       kernel_size=kernel_size,\n",
    "                                                       stride=stride,\n",
    "                                                       padding=padding),\n",
    "                                             #PixelShuffle(upscale_factor=2),\n",
    "                                             up_2Dsample(upscale_factor=2),\n",
    "                                             nn.InstanceNorm2d(num_features=out_channels,\n",
    "                                                               affine=True))\n",
    "    def forward(self, input):        \n",
    "        return self.convLayer(input) * torch.sigmoid(self.convLayer_gates(input))\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,\n",
    "                               out_channels=128,\n",
    "                               kernel_size=[5,15],\n",
    "                               stride=1,\n",
    "                               padding=[2,7])\n",
    "\n",
    "        self.conv1_gates = nn.Conv2d(in_channels=1,\n",
    "                               out_channels=128,\n",
    "                               kernel_size=[5,15],\n",
    "                               stride=1,\n",
    "                               padding=[2,7])\n",
    "\n",
    "        # Downsample Layer\n",
    "        self.downSample1 = downSample_Generator(in_channels=128,\n",
    "                                                out_channels=256,\n",
    "                                                kernel_size=5,\n",
    "                                                stride=2,\n",
    "                                                padding=2)\n",
    "\n",
    "        self.downSample2 = downSample_Generator(in_channels=256,\n",
    "                                                out_channels=512,\n",
    "                                                kernel_size=5,\n",
    "                                                stride=2,\n",
    "                                                padding=2)\n",
    "        #reshape\n",
    "        self.conv2 = nn.Conv1d(in_channels=3072,\n",
    "                               out_channels=512,\n",
    "                               kernel_size=1,\n",
    "                               stride=1)\n",
    "\n",
    "        # Residual Blocks\n",
    "        self.residualLayer1 = ResidualLayer(in_channels=512,\n",
    "                                            out_channels=1024,\n",
    "                                            kernel_size=3,\n",
    "                                            stride=1,\n",
    "                                            padding=1)\n",
    "        self.residualLayer2 = ResidualLayer(in_channels=512,\n",
    "                                            out_channels=1024,\n",
    "                                            kernel_size=3,\n",
    "                                            stride=1,\n",
    "                                            padding=1)\n",
    "        self.residualLayer3 = ResidualLayer(in_channels=512,\n",
    "                                            out_channels=1024,\n",
    "                                            kernel_size=3,\n",
    "                                            stride=1,\n",
    "                                            padding=1)\n",
    "    def forward(self, input):\n",
    "        # GLU\n",
    "        input = input.unsqueeze(1)\n",
    "        conv1 = self.conv1(input) * torch.sigmoid(self.conv1_gates(input))\n",
    "        downsample1 = self.downSample1(conv1)\n",
    "        downsample2 = self.downSample2(downsample1)\n",
    "        downsample3 = downsample2.view([downsample2.shape[0],-1,downsample2.shape[3]])\n",
    "        downsample3 = self.conv2(downsample3)\n",
    "        \n",
    "        residual_layer_1 = self.residualLayer1(downsample3)\n",
    "        residual_layer_2 = self.residualLayer2(residual_layer_1)\n",
    "        residual_layer_3 = self.residualLayer3(residual_layer_2)\n",
    "        return residual_layer_3\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.residualLayer4 = ResidualLayer(in_channels=512,\n",
    "                                            out_channels=1024,\n",
    "                                            kernel_size=3,\n",
    "                                            stride=1,\n",
    "                                            padding=1)\n",
    "        self.residualLayer5 = ResidualLayer(in_channels=512,\n",
    "                                            out_channels=1024,\n",
    "                                            kernel_size=3,\n",
    "                                            stride=1,\n",
    "                                            padding=1)\n",
    "        self.residualLayer6 = ResidualLayer(in_channels=512,\n",
    "                                            out_channels=1024,\n",
    "                                            kernel_size=3,\n",
    "                                            stride=1,\n",
    "                                            padding=1)\n",
    "        #reshape\n",
    "        self.conv3 = nn.Conv1d(in_channels=512,\n",
    "                               out_channels=3072,\n",
    "                               kernel_size=1,\n",
    "                               stride=1)\n",
    "\n",
    "\n",
    "        # UpSample Layer\n",
    "        self.upSample1 = upSample_Generator(in_channels=512,\n",
    "                                            out_channels=1024,\n",
    "                                            kernel_size=5,\n",
    "                                            stride=1,\n",
    "                                            padding=2)\n",
    "        \n",
    "        self.upSample2 = upSample_Generator(in_channels=1024,\n",
    "                                            out_channels=512,\n",
    "                                            kernel_size=5,\n",
    "                                            stride=1,\n",
    "                                            padding=2)\n",
    "\n",
    "        self.lastConvLayer = nn.Conv2d(in_channels=512,\n",
    "                                       out_channels=1,\n",
    "                                       kernel_size=[5,15],\n",
    "                                       stride=1,\n",
    "                                       padding=[2,7])\n",
    "\n",
    "    def forward(self, input):\n",
    "        # GLU\n",
    "        residual_layer_4 = self.residualLayer4(input)\n",
    "        residual_layer_5 = self.residualLayer5(residual_layer_4)\n",
    "        residual_layer_6 = self.residualLayer6(residual_layer_5)\n",
    "        residual_layer_6 = self.conv3(residual_layer_6)\n",
    "        residual_layer_6 = residual_layer_6.view([downsample2.shape[0],downsample2.shape[1],downsample2.shape[2],downsample2.shape[3]])\n",
    "        \n",
    "        upSample_layer_1 = self.upSample1(residual_layer_6)\n",
    "        upSample_layer_2 = self.upSample2(upSample_layer_1)\n",
    "        output = self.lastConvLayer(upSample_layer_2)\n",
    "        output = output.view([output.shape[0],-1,output.shape[3]])\n",
    "        return output\n",
    "\n",
    "\n",
    "class DownSample_Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(DownSample_Discriminator, self).__init__()\n",
    "\n",
    "        self.convLayer = nn.Sequential(nn.Conv2d(in_channels=in_channels,\n",
    "                                                 out_channels=out_channels,\n",
    "                                                 kernel_size=kernel_size,\n",
    "                                                 stride=stride,\n",
    "                                                 padding=padding),\n",
    "                                       nn.InstanceNorm2d(num_features=out_channels,\n",
    "                                                         affine=True))\n",
    "        self.convLayerGates = nn.Sequential(nn.Conv2d(in_channels=in_channels,\n",
    "                                                      out_channels=out_channels,\n",
    "                                                      kernel_size=kernel_size,\n",
    "                                                      stride=stride,\n",
    "                                                      padding=padding),\n",
    "                                            nn.InstanceNorm2d(num_features=out_channels,\n",
    "                                                              affine=True))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # GLU\n",
    "        return self.convLayer(input) * torch.sigmoid(self.convLayerGates(input))\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.convLayer1 = nn.Conv2d(in_channels=1,\n",
    "                                    out_channels=128,\n",
    "                                    kernel_size=[3, 3],\n",
    "                                    stride=[1, 1])\n",
    "        self.convLayer1_gates = nn.Conv2d(in_channels=1,\n",
    "                                          out_channels=128,\n",
    "                                          kernel_size=[3, 3],\n",
    "                                          stride=[1, 1])\n",
    "\n",
    "        # Note: Kernel Size have been modified in the PyTorch implementation\n",
    "        # compared to the actual paper, as to retain dimensionality. Unlike,\n",
    "        # TensorFlow, PyTorch doesn't have padding='same', hence, kernel sizes\n",
    "        # were altered to retain the dimensionality after each layer\n",
    "\n",
    "        # DownSample Layer\n",
    "        self.downSample1 = DownSample_Discriminator(in_channels=128,\n",
    "                                                    out_channels=256,\n",
    "                                                    kernel_size=[3, 3],\n",
    "                                                    stride=[2, 2],\n",
    "                                                    padding=0)\n",
    "\n",
    "        self.downSample2 = DownSample_Discriminator(in_channels=256,\n",
    "                                                    out_channels=512,\n",
    "                                                    kernel_size=[3, 3],\n",
    "                                                    stride=[2, 2],\n",
    "                                                    padding=0)\n",
    "\n",
    "        self.downSample3 = DownSample_Discriminator(in_channels=512,\n",
    "                                                    out_channels=1024,\n",
    "                                                    kernel_size=[3, 3],\n",
    "                                                    stride=[2, 2],\n",
    "                                                    padding=0)\n",
    "\n",
    "        self.downSample4 = DownSample_Discriminator(in_channels=1024,\n",
    "                                                    out_channels=1024,\n",
    "                                                    kernel_size=[1, 5],\n",
    "                                                    stride=[1, 1],\n",
    "                                                    padding=[0, 2])\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        self.fc = nn.Linear(in_features=1024,\n",
    "                            out_features=1)\n",
    "\n",
    "        # output Layer\n",
    "        self.output_layer = nn.Conv2d(in_channels=1024,\n",
    "                                      out_channels=1,\n",
    "                                      kernel_size=[1, 3],\n",
    "                                      stride=[1, 1],\n",
    "                                      padding=[0, 1])\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input has shape [batch_size, num_features, time]\n",
    "        # discriminator requires shape [batchSize, 1, num_features, time]\n",
    "        input = input.unsqueeze(1)\n",
    "        # GLU\n",
    "        pad_input = nn.ZeroPad2d((1, 1, 1, 1))\n",
    "        layer1 = self.convLayer1(\n",
    "            pad_input(input)) * torch.sigmoid(self.convLayer1_gates(pad_input(input)))\n",
    "\n",
    "        pad_input = nn.ZeroPad2d((1, 0, 1, 0))\n",
    "        downSample1 = self.downSample1(pad_input(layer1))\n",
    "\n",
    "        pad_input = nn.ZeroPad2d((1, 0, 1, 0))\n",
    "        downSample2 = self.downSample2(pad_input(downSample1))\n",
    "\n",
    "        pad_input = nn.ZeroPad2d((1, 0, 1, 0))\n",
    "        downSample3 = self.downSample3(pad_input(downSample2))\n",
    "\n",
    "        downSample4 = self.downSample4(downSample3)\n",
    "        downSample4 = self.output_layer(downSample4)\n",
    "\n",
    "        downSample4 = downSample4.contiguous().permute(0, 2, 3, 1).contiguous()\n",
    "        # fc = torch.sigmoid(self.fc(downSample3))\n",
    "        # Taking off sigmoid layer to avoid vanishing gradient problem\n",
    "        #fc = self.fc(downSample4)\n",
    "        fc = torch.sigmoid(downSample4)\n",
    "        return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "logf0s_normalization = \"./cache/logf0s_normalization.npz\"\n",
    "mcep_normalization = \"./cache/mcep_normalization.npz\"\n",
    "coded_sps_A_norm = \"./cache/coded_sps_A_norm.pickle\"\n",
    "coded_sps_B_norm = \"./cache/coded_sps_B_norm.pickle\" \n",
    "resume_training_at = \"./cache/model_checkpoint/_CycleGAN_CheckPoint\"\n",
    "validation_A_dir = \"./data/vcc2016_training/evaluation_all/SF1/\" \n",
    "output_A_dir = \"./data/vcc2016_training/converted_sound/SF1\"\n",
    "validation_B_dir = \"./data/vcc2016_training/evaluation_all/TF2/\" \n",
    "output_B_dir = \"./data/vcc2016_training/converted_sound/TF2/\"\"\n",
    "# =================================================\n",
    "start_epoch = 0\n",
    "num_epochs = 5000\n",
    "mini_batch_size = 16\n",
    "dataset_A = loadPickleFile(coded_sps_A_norm)\n",
    "dataset_B = loadPickleFile(coded_sps_B_norm)\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Speech Parameters\n",
    "logf0s_normalization = np.load(logf0s_normalization)\n",
    "log_f0s_mean_A = logf0s_normalization['mean_A']\n",
    "log_f0s_std_A = logf0s_normalization['std_A']\n",
    "log_f0s_mean_B = logf0s_normalization['mean_B']\n",
    "log_f0s_std_B = logf0s_normalization['std_B']\n",
    "\n",
    "mcep_normalization = np.load(mcep_normalization)\n",
    "coded_sps_A_mean = mcep_normalization['mean_A']\n",
    "coded_sps_A_std = mcep_normalization['std_A']\n",
    "coded_sps_B_mean = mcep_normalization['mean_B']\n",
    "coded_sps_B_std = mcep_normalization['std_B']\n",
    "\n",
    "# Encoder and Decoder\n",
    "encoder_noCNN = Encoder().to(device)\n",
    "encoder_noRNN = Encoder().to(device)\n",
    "encoder_noCNNRNN = Encoder().to(device)\n",
    "decoder_2A_noCNN = Decoder().to(device)\n",
    "decoder_2A_noRNN = Decoder().to(device)\n",
    "decoder_2A_noCNNRNN = Decoder().to(device)\n",
    "decoder_2B_noCNN = Decoder().to(device)\n",
    "decoder_2B_noRNN = Decoder().to(device)\n",
    "decoder_2B_noCNNRNN = Decoder().to(device)\n",
    "\n",
    "# Discriminator\n",
    "cnn_discriminator = CNN_Discriminator().to(device)\n",
    "rnn_discriminator = RNN_Discriminator().to(device)\n",
    "realfake_discriminator = RealFake_Discriminator().to(device)\n",
    "\n",
    "# Loss Functions\n",
    "criterion_mse = torch.nn.MSELoss()\n",
    "\n",
    "# Initial learning rates\n",
    "generator_lr = 0.0002\n",
    "discriminator_lr = 0.0001\n",
    "\n",
    "# Learning rate decay\n",
    "generator_lr_decay = generator_lr / 200000\n",
    "discriminator_lr_decay = discriminator_lr / 200000\n",
    "\n",
    "# Optimizers\n",
    "def get_optimizer(one_module, learning_rate):\n",
    "    return torch.optim.Adam(list(one_module.parameters()), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "encoder_noCNN_optimizer = get_optimizer(encoder_noCNN, generator_lr)\n",
    "encoder_noRNN_optimizer = get_optimizer(encoder_noRNN, generator_lr)\n",
    "encoder_noCNNRNN_optimizer = get_optimizer(encoder_noCNNRNN, generator_lr)\n",
    "\n",
    "decoder_2A_noCNN_optimizer = get_optimizer(decoder_2A_noCNN, generator_lr)\n",
    "decoder_2A_noRNN_optimizer = get_optimizer(decoder_2A_noRNN, generator_lr)\n",
    "decoder_2A_noCNNRNN_optimizer = get_optimizer(decoder_2A_noCNNRNN, generator_lr)\n",
    "decoder_2B_noCNN_optimizer = get_optimizer(decoder_2B_noCNN, generator_lr)\n",
    "decoder_2B_noRNN_optimizer = get_optimizer(decoder_2B_noRNN, generator_lr)\n",
    "decoder_2B_noCNNRNN_optimizer = get_optimizer(decoder_2B_noCNNRNN, generator_lr)\n",
    "\n",
    "realfake_discriminator_optimizer = get_optimizer(realfake_discriminator, discriminator_lr)\n",
    "cnn_discriminator_optimizer = get_optimizer(cnn_discriminator, discriminator_lr)\n",
    "rnn_discriminator_optimizer = get_optimizer(rnn_discriminator, discriminator_lr)\n",
    "\n",
    "\n",
    "# To Load save previously saved models\n",
    "modelCheckpoint = model_checkpoint\n",
    "\n",
    "# Validation set Parameters\n",
    "validation_A_dir = validation_A_dir\n",
    "output_A_dir = output_A_dir\n",
    "validation_B_dir = validation_B_dir\n",
    "output_B_dir = output_B_dir\n",
    "\n",
    "# Storing Discriminatior and Generator Loss\n",
    "generator_loss_store = []\n",
    "discriminator_loss_store = []\n",
    "cnn_discriminator_loss_store = []\n",
    "rnn_discriminator_loss_store = []\n",
    "\n",
    "file_name = 'log_store_non_sigmoid.txt'\n",
    "\n",
    "if restart_training_at is not None:\n",
    "    # Training will resume from previous checkpoint\n",
    "    start_epoch = loadModel(restart_training_at)\n",
    "    print(\"Training resumed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def adjust_lr_rate(optimizer, name='generator'):\n",
    "    if name == 'generator':\n",
    "        generator_lr = max(\n",
    "            0., generator_lr - generator_lr_decay)\n",
    "        for param_groups in optimizer.param_groups:\n",
    "            param_groups['lr'] = generator_lr\n",
    "    else:\n",
    "        discriminator_lr = max(\n",
    "            0., discriminator_lr - discriminator_lr_decay)\n",
    "        for param_groups in optimizer.param_groups:\n",
    "            param_groups['lr'] = discriminator_lr\n",
    "\n",
    "def reset_grad():\n",
    "    encoder_noCNN_optimizer.zero_grad()\n",
    "    encoder_noRNN_optimizer.zero_grad()\n",
    "    encoder_noCNNRNN_optimizer.zero_grad()\n",
    "    \n",
    "    decoder_2A_noCNN_optimizer.zero_grad()\n",
    "    decoder_2A_noRNN_optimizer.zero_grad()\n",
    "    decoder_2A_noCNNRNN_optimizer.zero_grad()\n",
    "    decoder_2B_noCNN_optimizer.zero_grad()\n",
    "    decoder_2B_noRNN_optimizer.zero_grad()\n",
    "    decoder_2B_noCNNRNN_optimizer.zero_grad()\n",
    "    \n",
    "    realfake_discriminator_optimizer.zero_grad()\n",
    "    cnn_discriminator_optimizer.zero_grad()\n",
    "    rnn_discriminator_optimizer.zero_grad()\n",
    "\n",
    "def savePickle(variable, fileName):\n",
    "    with open(fileName, 'wb') as f:\n",
    "        pickle.dump(variable, f)\n",
    "\n",
    "def loadPickleFile(fileName):\n",
    "    with open(fileName, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def store_to_file(doc):\n",
    "    doc = doc + \"\\n\"\n",
    "    with open(file_name, \"a\") as myfile:\n",
    "        myfile.write(doc)\n",
    "\n",
    "# def saveModelCheckPoint(self, epoch, PATH):\n",
    "#     torch.save({\n",
    "#         'epoch': epoch,\n",
    "#         'generator_loss_store': generator_loss_store,\n",
    "#         'discriminator_loss_store': discriminator_loss_store,\n",
    "#         'model_genA2B_state_dict': generator_A2B.state_dict(),\n",
    "#         'model_genB2A_state_dict': generator_B2A.state_dict(),\n",
    "#         'model_discriminatorA': discriminator_A.state_dict(),\n",
    "#         'model_discriminatorB': discriminator_B.state_dict(),\n",
    "#         'generator_optimizer': generator_optimizer.state_dict(),\n",
    "#         'discriminator_optimizer': discriminator_optimizer.state_dict()\n",
    "#     }, PATH)\n",
    "\n",
    "# def loadModel(PATH):\n",
    "#     checkPoint = torch.load(PATH)\n",
    "#     generator_A2B.load_state_dict(\n",
    "#         state_dict=checkPoint['model_genA2B_state_dict'])\n",
    "#     generator_B2A.load_state_dict(\n",
    "#         state_dict=checkPoint['model_genB2A_state_dict'])\n",
    "#     discriminator_A.load_state_dict(\n",
    "#         state_dict=checkPoint['model_discriminatorA'])\n",
    "#     discriminator_B.load_state_dict(\n",
    "#         state_dict=checkPoint['model_discriminatorB'])\n",
    "#     generator_optimizer.load_state_dict(\n",
    "#         state_dict=checkPoint['generator_optimizer'])\n",
    "#     discriminator_optimizer.load_state_dict(\n",
    "#         state_dict=checkPoint['discriminator_optimizer'])\n",
    "#     epoch = int(checkPoint['epoch']) + 1\n",
    "#     generator_loss_store = checkPoint['generator_loss_store']\n",
    "#     discriminator_loss_store = checkPoint['discriminator_loss_store']\n",
    "#     return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Begins...\n",
    "\n",
    "# for realA, realB:\n",
    "#   real -> embeddings -> fakeAB, fakeAA -> identity_loss\n",
    "#   forback_AB (True) -> update AB_disc -> forback_RF (True) -> update RF_disc\n",
    "#   zerograd encoder decoders\n",
    "#   forback_AB (False) -> forback_RF (False) -> identity_loss.backward\n",
    "#   fakeAB.Encoder.DecoderA -> fakeABA -> cycle_loss -> cycle_loss.backward\n",
    "#   encoder & decoder update\n",
    "\n",
    "# for realB, realA:\n",
    "#   real -> embeddings -> fakeBA, fakeBB -> identity_loss\n",
    "#   forback_AB (True) -> update AB_disc -> forback_RF (True) -> update RF_disc\n",
    "#   zerograd encoder decoders\n",
    "#   forback_AB (False) -> forback_RF (False) -> identity_loss.backward\n",
    "#   fakeBA.Encoder.DecoderB -> fakeBAB -> cycle_loss -> cycle_loss.backward\n",
    "#   encoder & decoder update\n",
    "\n",
    "def emb_forward_backward_AB_discriminator(embeddings, isA=True, gradients_for_discriminator=True):\n",
    "    cnn_discriminator_optimizer.zero_grad()\n",
    "    rnn_discriminator_optimizer.zero_grad()\n",
    "    \n",
    "    emb_noCNN, emb_noRNN, emb_noCNNRNN = embeddings\n",
    "    \n",
    "    true_pred = 0.0 if isA else 1.0\n",
    "    \n",
    "    target_cnn_01 = true_pred if gradients_for_discriminator else 0.5\n",
    "    target_cnn_10 = true_pred if gradients_for_discriminator else true_pred\n",
    "    target_cnn_00 = true_pred if gradients_for_discriminator else 0.5\n",
    "    \n",
    "    target_rnn_01 = true_pred if gradients_for_discriminator else true_pred\n",
    "    target_rnn_10 = true_pred if gradients_for_discriminator else 0.5\n",
    "    target_rnn_00 = true_pred if gradients_for_discriminator else 0.5\n",
    "    \n",
    "    # forward CNN discriminator for all 3 embeddings\n",
    "    pred_noCNN = cnn_discriminator(emb_noCNN)\n",
    "    d_loss = torch.mean((target_cnn_01 - pred_noCNN) ** 2)\n",
    "    d_loss.backward()\n",
    "    \n",
    "    pred_noRNN = cnn_discriminator(emb_noRNN)\n",
    "    d_loss = torch.mean((target_cnn_10 - pred_noRNN) ** 2)\n",
    "    d_loss.backward()\n",
    "    \n",
    "    pred_noCNNRNN = cnn_discriminator(emb_noCNNRNN)\n",
    "    d_loss = torch.mean((target_cnn_00 - pred_noCNNRNN) ** 2)\n",
    "    d_loss.backward()\n",
    "    \n",
    "    # forward RNN discriminator for all 3 embeddings\n",
    "    pred_noCNN = rnn_discriminator(emb_noCNN)\n",
    "    d_loss = torch.mean((target_rnn_01 - pred_noCNN) ** 2)\n",
    "    d_loss.backward()\n",
    "    \n",
    "    pred_noRNN = rnn_discriminator(emb_noRNN)\n",
    "    d_loss = torch.mean((target_rnn_10 - pred_noRNN) ** 2)\n",
    "    d_loss.backward()\n",
    "    \n",
    "    pred_noCNNRNN = rnn_discriminator(emb_noCNNRNN)\n",
    "    d_loss = torch.mean((target_rnn_00 - pred_noCNNRNN) ** 2)\n",
    "    d_loss.backward()\n",
    "    \n",
    "\n",
    "def update_AB_discriminator():\n",
    "    cnn_discriminator_optimizer.step()\n",
    "    rnn_discriminator_optimizer.step()\n",
    "    \n",
    "\n",
    "def fakeVoice_AB_forward_backward_RealFake_discriminator(fakes, real, gradients_for_discriminator=True):\n",
    "    realfake_discriminator_optimizer.zero_grad()\n",
    "    \n",
    "    fake_noCNN, fake_noRNN, fake_noCNNRNN = fakes\n",
    "    \n",
    "    pred = realfake_discriminator(fake_noCNN)\n",
    "    d_loss = torch.mean((0.0 - pred) ** 2)\n",
    "    d_loss.backward()\n",
    "    \n",
    "    pred = realfake_discriminator(fake_noRNN)\n",
    "    d_loss = torch.mean((0.0 - pred) ** 2)\n",
    "    d_loss.backward()\n",
    "    \n",
    "    pred = realfake_discriminator(fake_noCNNRNN)\n",
    "    d_loss = torch.mean((0.0 - pred) ** 2)\n",
    "    d_loss.backward()\n",
    "    \n",
    "    # if we are running this func for generator gradients, skip real input\n",
    "    # because gradient doesn't flow to generators\n",
    "    if gradients_for_discriminator: \n",
    "        pred = realfake_discriminator(real)\n",
    "        d_loss = torch.mean(3 * (1.0 - pred) ** 2)\n",
    "        d_loss.backward()\n",
    "    \n",
    "\n",
    "def update_RealFake_discriminator():\n",
    "    realfake_discriminator_optimizer.step()\n",
    "\n",
    "\n",
    "# for realA, realB:\n",
    "#   real -> embeddings -> fakeAB, fakeAA -> identity_loss\n",
    "#   forback_AB (True) -> update AB_disc -> forback_RF (True) -> update RF_disc\n",
    "#   zerograd encoder decoders\n",
    "#   forback_AB (False) -> forback_RF (False) -> identity_loss.backward\n",
    "#   fakeAB.Encoder.DecoderA -> fakeABA -> cycle_loss -> cycle_loss.backward\n",
    "#   encoder & decoder update\n",
    "\n",
    "# for realB, realA:\n",
    "#   real -> embeddings -> fakeBA, fakeBB -> identity_loss\n",
    "#   forback_AB (True) -> update AB_disc -> forback_RF (True) -> update RF_disc\n",
    "#   zerograd encoder decoders\n",
    "#   forback_AB (False) -> forback_RF (False) -> identity_loss.backward\n",
    "#   fakeBA.Encoder.DecoderB -> fakeBAB -> cycle_loss -> cycle_loss.backward\n",
    "#   encoder & decoder update\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    start_time_epoch = time.time()\n",
    "\n",
    "    # Constants\n",
    "    cycle_loss_lambda = 10\n",
    "    identity_loss_lambda = 5\n",
    "    #if epoch>20:#\n",
    "        #cycle_loss_lambda = 15#\n",
    "        #identity_loss_lambda = 0#\n",
    "\n",
    "    # Preparing Dataset\n",
    "    n_samples = len(dataset_A)\n",
    "\n",
    "    dataset = trainingDataset(datasetA=dataset_A,\n",
    "                              datasetB=dataset_B,\n",
    "                              n_frames=128)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                               batch_size=mini_batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               drop_last=False)\n",
    "\n",
    "    for i, (real_A, real_B) in enumerate(train_loader):\n",
    "\n",
    "        num_iterations = (\n",
    "            n_samples // mini_batch_size) * epoch + i\n",
    "        # print(\"iteration no: \", num_iterations, epoch)\n",
    "\n",
    "        if num_iterations > 10000:\n",
    "            identity_loss_lambda = 0\n",
    "        if num_iterations > start_decay:\n",
    "            adjust_lr_rate(\n",
    "                generator_optimizer, name='generator')\n",
    "            adjust_lr_rate(\n",
    "                generator_optimizer, name='discriminator')\n",
    "\n",
    "        real_A = real_A.to(device).float()\n",
    "        real_B = real_B.to(device).float()\n",
    "        \n",
    "        # ========================================\n",
    "        # for realA, realB:\n",
    "        reset_grad();\n",
    "        \n",
    "        #   real -> embeddings -> fakeAB, fakeAA\n",
    "        embedding_A_noCNN = encoder_noCNN(real_A)\n",
    "        embedding_A_noRNN = encoder_noRNN(real_A)\n",
    "        embedding_A_noCNNRNN = encoder_noCNNRNN(real_A)\n",
    "        embeddings = (embedding_A_noCNN, embedding_A_noRNN, embedding_A_noCNNRNN)\n",
    "        \n",
    "        fakeAB_noCNN = decoder_2B_noCNN(embedding_A_noCNN)\n",
    "        fakeAB_noRNN = decoder_2B_noRNN(embedding_A_noRNN)\n",
    "        fakeAB_noCNNRNN = decoder_2B_noCNNRNN(embedding_A_noCNNRNN)\n",
    "        fakesAB = (fakeAB_noCNN, fakeAB_noRNN, fakeAB_noCNNRNN)\n",
    "        \n",
    "        fakeAA_noCNN = decoder_2A_noCNN(embedding_A_noCNN)\n",
    "        fakeAA_noRNN = decoder_2A_noRNN(embedding_A_noRNN)\n",
    "        fakeAA_noCNNRNN = decoder_2A_noCNNRNN(embedding_A_noCNNRNN)\n",
    "        fakesAA = (fakeAA_noCNN, fakeAA_noRNN, fakeAA_noCNNRNN)\n",
    "        \n",
    "        #   forback_AB (True) -> update AB_disc -> forback_RF (True) -> update RF_disc\n",
    "        emb_forward_backward_AB_discriminator(embeddings, isA=True, gradients_for_discriminator=True)\n",
    "        update_AB_discriminator()\n",
    "        \n",
    "        fakeVoice_AB_forward_backward_RealFake_discriminator(fakesAB, real_B, gradients_for_discriminator=True)\n",
    "        update_RealFake_discriminator()\n",
    "        \n",
    "        #   zerograd encoder decoders (can also zero grad everything since discriminators have been updated)\n",
    "        reset_grad()\n",
    "        \n",
    "        #   forback_AB (False) -> forback_RF (False) -> identity_loss.backward\n",
    "        emb_forward_backward_AB_discriminator(embeddings, isA=True, gradients_for_discriminator=False)\n",
    "        fakeVoice_AB_forward_backward_RealFake_discriminator(fakesAB, real_B, gradients_for_discriminator=False)\n",
    "        \n",
    "        identityLoss_noCNN = torch.mean(torch.abs(real_A - fakeAA_noCNN))\n",
    "        identityLoss_noRNN = torch.mean(torch.abs(real_A - fakeAA_noRNN))\n",
    "        identityLoss_noCNNRNN = torch.mean(torch.abs(real_A - fakeAA_noCNNRNN))\n",
    "        identityLoss = (identityLoss_noCNN + identityLoss_noRNN + identityLoss_noCNNRNN) / 3.0\n",
    "        identityLoss.backward()\n",
    "        \n",
    "        #   fakeAB.Encoder.DecoderA -> fakeABA -> cycle_loss -> cycle_loss.backward\n",
    "        fakeABA_noCNN = decoder_2A_noCNN(encoder_noCNN(fakeAB_noCNN))\n",
    "        fakeABA_noRNN = decoder_2A_noRNN(encoder_noRNN(fakeAB_noRNN))\n",
    "        fakeABA_noCNNRNN = decoder_2A_noCNNRNN(encoder_noCNNRNN(fakeAB_noCNNRNN))\n",
    "        \n",
    "        cycleLoss_noCNN = torch.mean(torch.abs(real_A - fakeABA_noCNN))\n",
    "        cycleLoss_noRNN = torch.mean(torch.abs(real_A - fakeABA_noRNN))\n",
    "        cycleLoss_noCNNRNN = torch.mean(torch.abs(real_A - fakeABA_noCNNRNN))\n",
    "        cycleLoss = (cycleLoss_noCNN + cycleLoss_noRNN + cycleLoss_noCNNRNN) / 3.0\n",
    "        cycleLoss.backward()\n",
    "        \n",
    "        #   encoder & decoder update\n",
    "        encoder_noCNN_optimizer.step()\n",
    "        encoder_noRNN_optimizer.step()\n",
    "        encoder_noCNNRNN_optimizer.step()\n",
    "        decoder_2A_noCNN_optimizer.step()\n",
    "        decoder_2A_noRNN_optimizer.step()\n",
    "        decoder_2A_noCNNRNN_optimizer.step()\n",
    "        decoder_2B_noCNN_optimizer.step()\n",
    "        decoder_2B_noRNN_optimizer.step()\n",
    "        decoder_2B_noCNNRNN_optimizer.step()\n",
    "        \n",
    "        \n",
    "        # ========================================\n",
    "        # for realB, realA:\n",
    "        reset_grad();\n",
    "        \n",
    "        #   real -> embeddings -> fakeBA, fakeBB\n",
    "        embedding_B_noCNN = encoder_noCNN(real_B)\n",
    "        embedding_B_noRNN = encoder_noRNN(real_B)\n",
    "        embedding_B_noCNNRNN = encoder_noCNNRNN(real_B)\n",
    "        embeddings = (embedding_B_noCNN, embedding_B_noRNN, embedding_B_noCNNRNN)\n",
    "        \n",
    "        fakeBA_noCNN = decoder_2A_noCNN(embedding_B_noCNN)\n",
    "        fakeBA_noRNN = decoder_2A_noRNN(embedding_B_noRNN)\n",
    "        fakeBA_noCNNRNN = decoder_2A_noCNNRNN(embedding_B_noCNNRNN)\n",
    "        fakesBA = (fakeBA_noCNN, fakeBA_noRNN, fakeBA_noCNNRNN)\n",
    "        \n",
    "        fakeBB_noCNN = decoder_2B_noCNN(embedding_B_noCNN)\n",
    "        fakeBB_noRNN = decoder_2B_noRNN(embedding_B_noRNN)\n",
    "        fakeBB_noCNNRNN = decoder_2B_noCNNRNN(embedding_B_noCNNRNN)\n",
    "        fakesBB = (fakeBB_noCNN, fakeBB_noRNN, fakeBB_noCNNRNN)\n",
    "        \n",
    "        #   forback_AB (True) -> update AB_disc -> forback_RF (True) -> update RF_disc\n",
    "        emb_forward_backward_AB_discriminator(embeddings, isA=False, gradients_for_discriminator=True)\n",
    "        update_AB_discriminator()\n",
    "        \n",
    "        fakeVoice_AB_forward_backward_RealFake_discriminator(fakesBA, real_A, gradients_for_discriminator=True)\n",
    "        update_RealFake_discriminator()\n",
    "        \n",
    "        #   zerograd encoder decoders (can also zero grad everything since discriminators have been updated)\n",
    "        reset_grad()\n",
    "        \n",
    "        #   forback_AB (False) -> forback_RF (False) -> identity_loss.backward\n",
    "        emb_forward_backward_AB_discriminator(embeddings, isA=False, gradients_for_discriminator=False)\n",
    "        fakeVoice_AB_forward_backward_RealFake_discriminator(fakesBA, real_A, gradients_for_discriminator=False)\n",
    "        \n",
    "        identityLoss_noCNN = torch.mean(torch.abs(real_B - fakeBB_noCNN))\n",
    "        identityLoss_noRNN = torch.mean(torch.abs(real_B - fakeBB_noRNN))\n",
    "        identityLoss_noCNNRNN = torch.mean(torch.abs(real_B - fakeBB_noCNNRNN))\n",
    "        identityLoss = (identityLoss_noCNN + identityLoss_noRNN + identityLoss_noCNNRNN) / 3.0\n",
    "        identityLoss.backward()\n",
    "        \n",
    "        #   fakeBA.Encoder.DecoderB -> fakeBAB -> cycle_loss -> cycle_loss.backward\n",
    "        fakeBAB_noCNN = decoder_2B_noCNN(encoder_noCNN(fakeBA_noCNN))\n",
    "        fakeBAB_noRNN = decoder_2B_noRNN(encoder_noRNN(fakeBA_noRNN))\n",
    "        fakeBAB_noCNNRNN = decoder_2B_noCNNRNN(encoder_noCNNRNN(fakeBA_noCNNRNN))\n",
    "        \n",
    "        cycleLoss_noCNN = torch.mean(torch.abs(real_B - fakeBAB_noCNN))\n",
    "        cycleLoss_noRNN = torch.mean(torch.abs(real_B - fakeBAB_noRNN))\n",
    "        cycleLoss_noCNNRNN = torch.mean(torch.abs(real_B - fakeBAB_noCNNRNN))\n",
    "        cycleLoss = (cycleLoss_noCNN + cycleLoss_noRNN + cycleLoss_noCNNRNN) / 3.0\n",
    "        cycleLoss.backward()\n",
    "        \n",
    "        #   encoder & decoder update\n",
    "        encoder_noCNN_optimizer.step()\n",
    "        encoder_noRNN_optimizer.step()\n",
    "        encoder_noCNNRNN_optimizer.step()\n",
    "        decoder_2A_noCNN_optimizer.step()\n",
    "        decoder_2A_noRNN_optimizer.step()\n",
    "        decoder_2A_noCNNRNN_optimizer.step()\n",
    "        decoder_2B_noCNN_optimizer.step()\n",
    "        decoder_2B_noRNN_optimizer.step()\n",
    "        decoder_2B_noCNNRNN_optimizer.step()\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
